<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>ARISE - Voice Assistant</title>
  <style>
    body {
      background: black;
      color: white;
      font-family: Arial, sans-serif;
      text-align: center;
      margin: 0;
      height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
      flex-direction: column;
    }
    .skull {
      font-size: 150px;
      position: relative;
    }
    .eyes {
      position: absolute;
      top: 35px;
      left: 50%;
      transform: translateX(-50%);
      display: flex;
      gap: 40px;
    }
    .eye {
      width: 25px;
      height: 25px;
      background: red;
      border-radius: 50%;
      box-shadow: 0 0 20px red;
    }
    .mouth {
      position: absolute;
      bottom: 30px;
      left: 50%;
      transform: translateX(-50%);
      width: 60px;
      height: 20px;
      background: white;
      border-radius: 5px;
      display: none;
    }
    #status {
      margin-top: 20px;
      font-size: 20px;
      color: lime;
    }
    button {
      margin-top: 20px;
      padding: 10px 20px;
      border: none;
      border-radius: 8px;
      background: lime;
      color: black;
      font-weight: bold;
      cursor: pointer;
    }
  </style>
</head>
<body>
  <div class="skull">
    üíÄ
    <div class="eyes">
      <div class="eye" id="eye1"></div>
      <div class="eye" id="eye2"></div>
    </div>
    <div class="mouth" id="mouth"></div>
  </div>

  <div id="status">Say "ARISE" to activate...</div>
  <button onclick="startAssistant()">Start Listening</button>

  <script>
    const statusText = document.getElementById("status");
    const mouth = document.getElementById("mouth");
    let isActivated = false;

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = false;
    recognition.lang = "en-US";

    // üîä Speak in Hindi using available voices
    const speak = (text) => {
      const utter = new SpeechSynthesisUtterance(text);
      utter.lang = "hi-IN"; // Hindi voice
      utter.pitch = 1;
      utter.rate = 1;

      // Try to use a Hindi voice if available
      const voices = speechSynthesis.getVoices();
      const hindiVoice = voices.find(voice => voice.lang === "hi-IN" || voice.name.toLowerCase().includes("hindi"));
      if (hindiVoice) {
        utter.voice = hindiVoice;
      }

      utter.onstart = () => { mouth.style.display = "block"; };
      utter.onend = () => { mouth.style.display = "none"; };
      speechSynthesis.speak(utter);
    };

    // üß† Assistant commands and identity
    function handleCommand(command) {
      if (command.includes("joke")) {
        const jokes = [
          "‡§è‡§ï ‡§ï‡§Ç‡§ï‡§æ‡§≤ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§®‡§π‡•Ä‡§Ç ‡§ó‡§Ø‡§æ? ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§â‡§∏‡§ï‡•á ‡§™‡§æ‡§∏ ‡§¶‡§ø‡§≤ ‡§®‡§π‡•Ä‡§Ç ‡§•‡§æ!",
          "‡§ï‡§Ç‡§™‡•ç‡§Ø‡•Ç‡§ü‡§∞ ‡§°‡•â‡§ï‡•ç‡§ü‡§∞ ‡§ï‡•á ‡§™‡§æ‡§∏ ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§ó‡§Ø‡§æ? ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§â‡§∏‡•á ‡§¨‡§π‡•Å‡§§ ‡§∏‡§æ‡§∞‡•á ‡§¨‡§æ‡§á‡§ü‡•ç‡§∏ ‡§π‡•ã ‡§∞‡§π‡•á ‡§•‡•á!",
          "‡§≠‡•Ç‡§§ ‡§ï‡•ã ‡§®‡•å‡§ï‡§∞‡•Ä ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•Ä? ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§â‡§∏‡§ï‡§æ ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§™‡§æ‡§∞‡§¶‡§∞‡•ç‡§∂‡•Ä ‡§•‡§æ!"
        ];
        speak(jokes[Math.floor(Math.random() * jokes.length)]);
      } else if (command.includes("what is your name") || command.includes("your name")) {
        speak("‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§Ö‡§∞‡§æ‡§á‡§ú‡§º ‡§π‡•à‡•§ ‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§µ‡•â‡§á‡§∏ ‡§Ö‡§∏‡§ø‡§∏‡•ç‡§ü‡•á‡§Ç‡§ü ‡§π‡•Ç‡§Å‡•§");
      } else if (command.includes("who made you") || command.includes("who created you")) {
        speak("‡§Æ‡•Å‡§ù‡•á ‡§è‡§ï ‡§°‡§ø‡§µ‡•á‡§≤‡§™‡§∞ ‡§®‡•á ‡§¨‡§®‡§æ‡§Ø‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§¨‡§π‡•Å‡§§ ‡§∏‡•ç‡§Æ‡§æ‡§∞‡•ç‡§ü ‡§π‡•à‡•§");
      } else if (command.includes("what can you do") || command.includes("about yourself")) {
        speak("‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§∏‡•Å‡§® ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å, ‡§Ü‡§™‡§ï‡•ã ‡§ú‡•ã‡§ï‡•ç‡§∏ ‡§∏‡•Å‡§®‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å, ‡§î‡§∞ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§≠‡•Ä ‡§¶‡•á ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å‡•§");
      } else if (command.includes("who is") || command.includes("what is")) {
        let query = command.replace("who is", "").replace("what is", "").trim();
        if (!query || query.length < 2) {
          speak("‡§ï‡•É‡§™‡§Ø‡§æ ‡§•‡•ã‡§°‡§º‡§æ ‡§î‡§∞ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§¨‡•ã‡§≤‡•á‡§Ç‡•§");
          return;
        }
        statusText.innerText = "Searching Wikipedia for " + query;
        fetch(`https://en.wikipedia.org/api/rest_v1/page/summary/${encodeURIComponent(query)}`)
          .then(res => res.json())
          .then(data => {
            if (data.extract) {
              speak(data.extract);
            } else {
              speak("‡§Æ‡§æ‡§´‡§º ‡§ï‡•Ä‡§ú‡§ø‡§è, ‡§Æ‡•Å‡§ù‡•á ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•Ä‡•§");
            }
          })
          .catch(() => speak("‡§ï‡•Å‡§õ ‡§ó‡§°‡§º‡§¨‡§°‡§º ‡§π‡•ã ‡§ó‡§à‡•§"));
      } else {
        speak("‡§Æ‡•à‡§Ç ‡§∏‡§Æ‡§ù ‡§®‡§π‡•Ä‡§Ç ‡§™‡§æ‡§Ø‡§æ‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§¶‡•ã‡§¨‡§æ‡§∞‡§æ ‡§¨‡•ã‡§≤‡•á‡§Ç‡•§");
      }
    }

    recognition.onresult = (event) => {
      const transcript = event.results[event.results.length - 1][0].transcript.toLowerCase().trim();
      console.log("Heard:", transcript);

      if (!isActivated && transcript.includes("arise")) {
        isActivated = true;
        statusText.innerText = "Activated üëª Waiting for your command...";
        speak("‡§Æ‡•à‡§Ç ‡§Ø‡§π‡§æ‡§Å ‡§π‡•Ç‡§Å‡•§ ‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç?");
      } else if (isActivated) {
        handleCommand(transcript);
        isActivated = false;
        statusText.innerText = "Say 'ARISE' to activate again...";
      }
    };

    recognition.onerror = (e) => {
      statusText.innerText = "Recognition Error: " + e.error;
      console.error(e);
    };

    function startAssistant() {
      if (!window.isSecureContext) {
        alert("‚ö†Ô∏è ‡§ï‡•É‡§™‡§Ø‡§æ HTTPS ‡§Ø‡§æ localhost ‡§∏‡•á ‡§á‡§∏ ‡§™‡•á‡§ú ‡§ï‡•ã ‡§ñ‡•ã‡§≤‡•á‡§Ç‡•§");
        statusText.innerText = "HTTPS ‡§Ø‡§æ localhost ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§π‡•à‡•§";
        return;
      }

      navigator.mediaDevices.getUserMedia({ audio: true })
        .then(() => {
          recognition.start();
          statusText.innerText = "Listening... Say 'ARISE'";
        })
        .catch((err) => {
          console.error("Microphone access denied:", err);
          statusText.innerText = "Microphone access denied.";
          speak("‡§Æ‡•Å‡§ù‡•á ‡§Æ‡§æ‡§á‡§ï ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§ö‡§æ‡§π‡§ø‡§è‡•§");
        });
    }

    // üü° Load voices early to avoid delay
    window.speechSynthesis.onvoiceschanged = () => {
      speechSynthesis.getVoices(); // preload voices
    };
  </script>
</body>
</html>
